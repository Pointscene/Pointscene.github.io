<!doctype html>
<html>
  <head>
    <style>
      body {
        padding: 20px;
        margin: 0px;
        background-color: #ddd;
        color: #365379;
        overflow-y: scroll;
        font-family: "Open Sans";
      }
    </style>
  </head>
  <body>
    <h1>
      Pointscene API documentation
    </h1>
    <h2>
      Introduction
    </h2>
    <p>
      Pointscene API provides tools to analyze, manage and stream reality capture data.<br />
      Please email us at support@pointscene.com for API access.
    </p>
    <p>
      Pointscene API has built-in support for point clouds, raster files, mesh* models, 
      images* and vector* files.
    </p>
    <p>
      The power of Pointscene API comes from fully customizable workflows.<br />
      Workflows can be used to convert data in to streaming formats, extract metadata and much more.
    </p>
    <h2>
      Quickstart
    </h2>
    <h3>
      Convert ortho mosaic to Cloud Optimized GeoTIFF (COG) for streaming TMS tiles
    </h3>
    <p>
      We will use the <code>createWorkflow</code> mutation to define the workflow tasks for the conversion.
    </p>
    <p>
      <code>
        mutation {
          createWorkflow(
            instanceId: <Instance Id>
            title: "Create COG for streaming TMS tiles"
            tasks: [
              {
                # Define input data to be downloaded from an external source
                name: "download"
                type: "web.download"
                args: {
                  url: <URL to ortho photo>
                }        
              }
              {
                # Run gdal.translate to generate COG
                name: "cog"
                type: "gdal.translate"
                args: {
                  of: "COG"
                  co: [
                    "BIGTIFF=IF_SAFER"
                  ]
                }
                # Define task input from "download"
                inputs: ["download"]
              }
              {
                # Extract metadata such as geographic boundary
                name: "info"
                type: "gdal.info"
                args: {}
                inputs: ["cog"]
              }
              {
                # Sync extracted metadata to the DB
                name: "sync"
                type: "resource.sync"
                args: {}
                inputs: ["info"]
              }
              {
                # Upload converted COG to storage
                name: "upload"
                type: "resource.upload"
                args: {}
                inputs: ["sync", "cog"]
              }
              {
                # Enable resource
                name: "enable"
                type: "resource.enable"
                args: {}
                inputs: ["sync"]
              }
            ]
          ) {
            id
          }
        }
      </code>
    </p>
    <h3>
      Convert point cloud file to a streaming format for use in browsers
    </h3>
    <p>
      We will use the <code>createWorkflow</code> mutation to define the workflow tasks for the conversion.
    </p>
    <p>
      <code>
        mutation {
          createWorkflow(
            instanceId: <Instance Id>
            title: "Create Potree structure for streaming point cloud"
            tasks: [
              {
                # Define input to be downloaded from the web
                name: "download"
                type: "web.download"
                args: {
                  url: <URL for pointcloud>
                }        
              }
              {
                # Run PotreeConverter on the downloaded data
                name: "potree"
                type: "potreeconverter.convert"
                args: {}
                inputs: ["download"]
              }
              {
                # Extract metadata
                name: "info"
                type: "pdal.info"
                args: {}
                inputs: ["download"]
              }
              {
                # Sync the metadata to the DB
                name: "sync"
                type: "resource.sync"
                args: {}
                inputs: ["info"]
              }
              {
                # Upload Potree files to storage
                name: "upload"
                type: "resource.upload"
                args: {}
                inputs: ["sync", "potree"]
              }
              {
                # Enable resource for streaming
                name: "enable"
                type: "resource.enable"
                args: {}
                inputs: ["sync"]
              }
            ]
          ) {
            id
          }
        }
        
      </code>
    </p>
    <h2>
      Workflows
    </h2>
    <p>
      Workflows and queries are consumed through <a href="/graphql/index.html">Pointscene GraphQL API</a>.
    </p>
    <p>
      Workflows are built from tasks by linking them together as graphs.<br />
      You can find more information on building custom workflows from 
      <a href="/workflows/index.html">here*</a>.
    </p>
    <h2>
      User authentication
    </h2>
    <p>
      User authentication (OAuth2.0) is handled via REST endpoints. 
      REST API documentation can be found <a href="/rest/index.html">here*</a>.
    </p>
    <h2>Support</h2>
    <p>
      You can contact us at support@pointscene.com.
    </p>
    <h2>Links</h2>
    <p>
      <a href="https://api.pointscene.com/graphql">Pointscene GraphQL API playground</a><br />
      <a href="/graphql/index.html">Pointscene GraphQL API documentation</a><br />
      <a href="/rest/index.html">Pointscene REST API documentation</a><br />
    </p>
    <p>
      <small>*) Coming soon</small>
    </p>
  </body>
</html>
